{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729b81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "from dotenv import  load_dotenv\n",
    "\n",
    "import numpy as np\n",
    "sys.path.append('../../system/')\n",
    "from get_similarity.utils.preprocess import preprocess\n",
    "# from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "# from langchain_chroma import Chroma\n",
    "from configs import JD_PATH, COLLECTION, DB_PATH\n",
    "\n",
    "from insert_chunks import *\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74461ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [i for i in os.listdir(\"data\") if i.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196235c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-4.1_resume.csv',\n",
       " 'o4-mini.csv',\n",
       " 'gpt-4.1-mini_resume.csv',\n",
       " 'o4-mini_format.csv',\n",
       " 'gpt-4.1-mini.csv',\n",
       " 'o4-mini_resume.csv',\n",
       " 'o3-mini_format.csv',\n",
       " 'o3-mini.csv',\n",
       " 'gpt-4.1.csv',\n",
       " 'gpt-4.1_format.csv',\n",
       " 'o3-mini_resume.csv',\n",
       " 'gpt-4.1-mini_format.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa0fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_example = pd.read_csv(\"data/\" + paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c3644e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cv_example</th>\n",
       "      <th>jd</th>\n",
       "      <th>generated_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "      <td>#####  **Job Type: Contract**\\n\\n##### **Job C...</td>\n",
       "      <td>Created CV:\\n\\nPersonal Information  \\nName: J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "      <td>Location\\n\\nRemote, USA\\n\\nType\\n\\nFull time\\n...</td>\n",
       "      <td>Created CV:\\n\\nPersonal Information  \\nName: J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "      <td>EvenUp is on a mission to support injury law f...</td>\n",
       "      <td>Created CV:\\n\\nPersonal Information  \\nName: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Skills • R • Python • SAP HANA • Tableau • SAP...</td>\n",
       "      <td>Riverbed. Empower the Experience:\\n\\nRiverbed,...</td>\n",
       "      <td>Created CV:\\n\\nAlexandra Johnson  \\nChicago, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "      <td>##  **Teamwork makes the stream work.**\\n\\n###...</td>\n",
       "      <td>Created CV:\\n\\nPersonal Information  \\nName: J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         cv_example  \\\n",
       "0   0  Skills * Programming Languages: Python (pandas...   \n",
       "1   1  Education Details \\r\\nMay 2013 to May 2017 B.E...   \n",
       "2   2  Areas of Interest Deep Learning, Control Syste...   \n",
       "3   3  Skills • R • Python • SAP HANA • Tableau • SAP...   \n",
       "4   4  Education Details \\r\\n MCA   YMCAUST,  Faridab...   \n",
       "\n",
       "                                                  jd  \\\n",
       "0  #####  **Job Type: Contract**\\n\\n##### **Job C...   \n",
       "1  Location\\n\\nRemote, USA\\n\\nType\\n\\nFull time\\n...   \n",
       "2  EvenUp is on a mission to support injury law f...   \n",
       "3  Riverbed. Empower the Experience:\\n\\nRiverbed,...   \n",
       "4  ##  **Teamwork makes the stream work.**\\n\\n###...   \n",
       "\n",
       "                                        generated_cv  \n",
       "0  Created CV:\\n\\nPersonal Information  \\nName: J...  \n",
       "1  Created CV:\\n\\nPersonal Information  \\nName: J...  \n",
       "2  Created CV:\\n\\nPersonal Information  \\nName: A...  \n",
       "3  Created CV:\\n\\nAlexandra Johnson  \\nChicago, I...  \n",
       "4  Created CV:\\n\\nPersonal Information  \\nName: J...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_example.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58716c15",
   "metadata": {},
   "source": [
    "<!-- # Prompting(llm-as-a-judge) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66156a",
   "metadata": {},
   "source": [
    "# LLM-judge structured-output, prompt 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82526d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b28ea75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skills_score 80\n",
      "experience_score: 70\n",
      "culture_fit_score: 60\n",
      "readability_score: 90\n",
      "generation_score: 75\n",
      "Reasoning:\n",
      " Skills Score: The candidate has Python, TensorFlow (a machine learning framework), and AWS (cloud service), which aligns well with the JD requirements, but TensorFlow is not explicitly mentioned and AWS is a broad cloud service; hence 80.\n",
      "Experience Score: The candidate has 1.5 years of AI project experience, slightly below the 2+ years required, so score is 70.\n",
      "Culture Fit Score: No explicit cultural values mentioned in JD or resume, but the candidate's background suggests some alignment with innovation and technical skills, so moderate score of 60.\n",
      "Readability Score: The resume is concise and clear with no grammatical issues, so 90.\n",
      "Generation Score: Overall, the resume is good but lacks some detail on projects and achievements, so 75.\n"
     ]
    }
   ],
   "source": [
    "# 1) OpenAI 클라이언트 초기화\n",
    "client = OpenAI()\n",
    "\n",
    "# 2) 출력 스키마 정의\n",
    "class ResumeEvaluation(BaseModel):\n",
    "    skills_score: int = Field(description=\"0-100: How well the applicant's skills match the JD requirements\")\n",
    "    experience_score: int = Field(description=\"0-100: Fit of years of experience and project background\")\n",
    "    culture_fit_score: int = Field(description=\"0-100: Cultural fit based on key values (e.g., collaboration, innovation)\")\n",
    "    readability_score: int = Field(description=\"0-100: Sentence clarity and overall readability\")\n",
    "    generation_score: int = Field(description=\"0-100: Overall quality of the generated resume\")\n",
    "    reasoning: str = Field(description=\"Reason for each score. Have to spperate by new line\")\n",
    "\n",
    "# 3) ChatCompletion 호출 & 파싱\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"You are an AI judge. Evaluate the resume against the job description and return JSON matching the ResumeEvaluation schema.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "Job Description:\n",
    "- Experience with Python, machine learning, and cloud services\n",
    "- Bachelor's degree in Computer Science\n",
    "- 2+ years of AI project experience\n",
    "\n",
    "Resume:\n",
    "- Name: Jane Doe\n",
    "- Skills: Python, TensorFlow, AWS\n",
    "- Experience: 1.5 years in AI projects at XYZ Inc.\n",
    "- Education: BSc in Computer Science from ABC University\n",
    "\"\"\"}\n",
    "    ],\n",
    "    response_format=ResumeEvaluation,  # Pydantic 모델 지정\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 4) 파싱된 결과 사용\n",
    "evaluation: ResumeEvaluation = completion.choices[0].message.parsed\n",
    "print(\"skills_score\", evaluation.skills_score)\n",
    "print(\"experience_score:\", evaluation.experience_score)\n",
    "print(\"culture_fit_score:\", evaluation.culture_fit_score)\n",
    "print(\"readability_score:\", evaluation.readability_score)\n",
    "print(\"generation_score:\", evaluation.generation_score)\n",
    "print(\"Reasoning:\\n\", evaluation.reasoning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b3f96d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created CV:\n",
      "\n",
      "Personal Information  \n",
      "Name: John A. Doe  \n",
      "Address: 1234 Elm Street, Austin, TX 78701  \n",
      "Phone: (512) 555‑1234  \n",
      "Email: john.a.doe@example.com  \n",
      "LinkedIn: linkedin.com/in/johna-doe  \n",
      "\n",
      "Education  \n",
      "Master of Science in Data Science, May 2018  \n",
      "University of Texas at Austin, Austin, TX  \n",
      "Bachelor of Science in Computer Science, May 2016  \n",
      "University of Texas at Austin, Austin, TX  \n",
      "\n",
      "Certifications  \n",
      "• Microsoft Certified: Azure AI Engineer Associate  \n",
      "• Microsoft Certified: Azure Data Engineer Associate  \n",
      "• Databricks Certified Associate Developer for Apache Spark 3.0  \n",
      "\n",
      "Technical Skills  \n",
      "Programming Languages:  \n",
      "• Python (pandas, numpy, scikit‑learn, PyTorch, TensorFlow)  \n",
      "• R (tidyverse, caret, mlr)  \n",
      "• C# (.NET Core), SQL (T‑SQL), JavaScript (Node.js)  \n",
      "\n",
      "Azure Services & Cloud Technologies:  \n",
      "• Azure Machine Learning (automated ML, MLOps)  \n",
      "• Azure Databricks (notebooks, Delta Lake, Spark)  \n",
      "• Azure Cognitive Services (Language, Vision, Speech SDKs)  \n",
      "• Azure Synapse Analy\n"
     ]
    }
   ],
   "source": [
    "print(one_example[\"generated_cv\"].iloc[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b69fe1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gen_cv(jd, gen_cv, model=\"gpt-4.1\", temperature=0):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"You are an impartial AI judge that evaluates a generated resume against a job description and outputs valid JSON\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Job Description:\n",
    "{jd}\n",
    "Generated Resume:\n",
    "{gen_cv}\n",
    "    \n",
    "###Guidelines###\n",
    "1. Generated Resume Do **NOT** copy or closely paraphrase sentences from the JD.\\\n",
    "      If such leakage is detected, set `generation_score` ≤ 30.\n",
    "2. Reward resumes that demonstrably cover the JD's required skills, experience, \\\n",
    "and education with higher `skills_score` and `experience_score`.\n",
    "3. Answer length alone does not guarantee a higher rank—concise, task-focused content should be rewarded with a higher readability_score.\n",
    "\n",
    "    \"\"\"}\n",
    "        ],\n",
    "        response_format=ResumeEvaluation,  # Pydantic 모델 지정\n",
    "        # temperature=temperature           #reasoning 모델은 temperature 지정 붋가\n",
    "    )\n",
    "    return completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8dd0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample = one_example.iloc[0]\n",
    "result = evaluate_gen_cv(one_sample[\"jd\"], one_sample[\"generated_cv\"], model=\"o3-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "731d03b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'skills_score': 95,\n",
       " 'experience_score': 90,\n",
       " 'culture_fit_score': 90,\n",
       " 'readability_score': 90,\n",
       " 'generation_score': 95,\n",
       " 'reasoning': 'The resume demonstrates a strong match with the technical skills required by the JD, including extensive use of Azure services for generative AI, machine learning, and data pipelines, resulting in a high skills score.\\nThe candidate has relevant professional experience (current contract role as Azure GenAI Engineer and experience at multiple firms) that aligns well with the 3+ years requirement and the responsibilities outlined, leading to a high experience score.\\nThe resume highlights collaboration with cross-functional teams, stakeholder engagement, and contributions to documentation and training, showcasing good cultural fit.\\nThe content is well-organized, clearly written and logically structured, thus meriting a high readability score.\\nThe overall quality of the generated resume is strong with comprehensive details and appropriate context, and it avoids closely paraphrasing the JD, leading to a high generation score.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f217a",
   "metadata": {},
   "source": [
    "<!-- # Evaluate full result -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69d554f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dataset = pd.read_csv(\"./data/gpt-4.1-mini_resume.csv\")\n",
    "resume_dataset = resume_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d79b658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.74s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in tqdm(range(len(resume_dataset))):\n",
    "    one_sample = resume_dataset.iloc[i]\n",
    "    # one_sample = resume_dataset.iloc[np.random.randint(0, len(resume_dataset))]\n",
    "\n",
    "    jd = one_sample[\"jd\"]\n",
    "    gen_cv = one_sample[\"generated_cv\"]\n",
    "    results.append(evaluate_gen_cv(jd, gen_cv=gen_cv, model=\"gpt-4.1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75308f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResumeEvaluation(skills_score=98, experience_score=97, culture_fit_score=96, readability_score=93, generation_score=92, reasoning=\"Skills Score: The candidate lists direct experience and knowledge in all key manufacturing processes and relevant technical/soft skills described in the JD, earning certifications in required areas.\\nExperience Score: States 12 months hands-on experience in manufacturing processes and clean room operations, specifically supporting wafer fabrication, directly matching the JD for an entry-level technician. Also documents participation in compressed shift schedules as required.\\nCulture Fit Score: The resume repeatedly references participation in development opportunities, the collaborative work environment, and continuous professional growth, aligning closely with the company's stated values of innovation, learning, and inclusivity.\\nReadability Score: The resume is well-structured, clear, and concise, using bullet points for clarity and logical section headings. Mild redundancies exist in benefits descriptions but the core information is presented effectively.\\nGeneration Score: The resume is original, does not copy or paraphrase JD sentences, and is tailored to the role. It closely and accurately reflects the requirements and culture promoted in the job posting without appearing formulaic or generic.\"),\n",
       " ResumeEvaluation(skills_score=95, experience_score=95, culture_fit_score=95, readability_score=90, generation_score=90, reasoning='Skills Score: The resume specifically lists customer service, cash handling, communication, teamwork, problem solving, adaptability, positive attitude, and reliability—all key skills from the JD, demonstrated with months of experience. Nearly perfect skill fit.\\nExperience Score: The applicant has 18 months as a Customer Service Associate at Albertsons (matching employer and role), and provides detailed achievements in line with daily expectations (cashiering, courtesy clerk, customer service). Well-aligned with background required.\\nCulture Fit Score: Shows clear alignment with key values like belonging, diversity/inclusion, teamwork, uplifting community, eagerness to learn, and putting people first—great cultural match.\\nReadability Score: The content is clear, with concise bullet points and no excessive/irrelevant details, though there are small grammatical issues (\"Exprience\" typo). Otherwise, strong readability overall.\\nGeneration Score: No evidence of improper copying; bullet points are original and relevant. Sentence structure and summary demonstrate direct experience, tailored to the role. Small deduction for typos and slightly repetitive employer listings, but overall a high-quality generated resume.'),\n",
       " ResumeEvaluation(skills_score=95, experience_score=95, culture_fit_score=90, readability_score=92, generation_score=90, reasoning='Skills Score: The resume lists all core skills required—customer service, cash handling, transaction processing, shift adaptability, and compliance. Some minor overlap with JD terms is noted but not direct copying.\\nExperience Score: The candidate is currently employed in the exact role and location as described in the JD. They have 1 year of experience in all relevant skills. Perfect fit.\\nCulture Fit Score: Resume demonstrates commitment to service, compliance, adaptability, and communication—values likely valued at Walmart, though explicit statements about teamwork and innovation are minimal.\\nReadability Score: The resume is logically structured, concise, and clear. Minor redundancy in listing skills/experience sections but overall highly readable.\\nGeneration Score: Resume draws clear connections between candidate’s experience and the JD while avoiding direct copying. Repetition of skills could be summarized, but overall presentation is strong.'),\n",
       " ResumeEvaluation(skills_score=95, experience_score=95, culture_fit_score=95, readability_score=93, generation_score=90, reasoning='Skills Score: The resume clearly demonstrates all core skills from the JD: customer service, teamwork, food handling, cashiering, community engagement, and a positive attitude, with direct evidence of experience in each area. \\nExperience Score: 2 years at Albertsons in relevant roles and multiple related projects (customer engagement, community outreach, training, flexible scheduling) provide direct job-fit experience; education requirement (high school diploma) is met.\\nCulture Fit Score: Numerous references to diversity, inclusion, community, learning, positive attitude, and collaboration align closely with the company values and desired culture.\\nReadability Score: The resume is structured, easy to read, and avoids large blocks of text; bullet points are well used; minor repetition present but mostly concise.\\nGeneration Score: The resume avoids direct copying from the JD and summarizes responsibilities and skills in original language; one or two phrases are close to the JD but not exact; overall, the quality is high and adheres to the guidelines.'),\n",
       " ResumeEvaluation(skills_score=90, experience_score=85, culture_fit_score=85, readability_score=80, generation_score=60, reasoning='Skills Score: The resume lists nearly all required and desired skills from the JD: communication, math, retail/customer service, stress/conflict management, cash control, team collaboration, and more. There is also mention of bilingual skills and food safety. \\nExperience Score: The candidate claims over 1 year in each relevant area and includes front-end management, employee coaching, and supervision at King Soopers (the actual target company), suggesting a strong fit for experience background. \\nCulture Fit Score: Resume references the company values (respect, honesty, inclusion, etc.) and relevant workplace behaviors (teamwork, safety, compliance), indicating cultural fit. \\nReadability Score: Resume is generally clear and lists skills directly, but sentence structure is sometimes choppy and suffers from repeated phrasing (\"Exprience - More than 1 year months\"). \\nGeneration Score: There is moderate JD copying/leakage problem in the company description (\"Committed to exceptional customer service, safety, and delivering food with care while embracing company values of respect, honesty, integrity, diversity, inclusion and safety\"), lowering the generation score as per guidelines 1. Otherwise, structure is coherent, so not minimal score, but penalized to 60.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ade58ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.36s/it]\n"
     ]
    }
   ],
   "source": [
    "#점수가 예상보다 너무 높아서 random index로 일부로 negative sample을 넣어 결과확인\n",
    "results = []\n",
    "for i in tqdm(range(len(resume_dataset))):\n",
    "    one_sample = resume_dataset.iloc[i]\n",
    "    cv_one_sample = resume_dataset.iloc[np.random.randint(0, len(resume_dataset))]\n",
    "\n",
    "    jd = one_sample[\"jd\"]\n",
    "    gen_cv = cv_one_sample[\"generated_cv\"]\n",
    "    results.append(evaluate_gen_cv(jd, gen_cv=gen_cv, model=\"gpt-4.1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07af974b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResumeEvaluation(skills_score=40, experience_score=35, culture_fit_score=80, readability_score=85, generation_score=70, reasoning=\"Skills Score: The resume shows basic customer service, compliance, shift work, and transaction processing but lacks direct technical manufacturing, photolithography, etch, or wafer fab experience. No cleanroom, semiconductor, or relevant technical process certification is listed. \\nExperience Score: Experience is primarily in retail (Walmart front end), not in manufacturing or wafer fab. No relevant manufacturing or technical projects/background, but strong shift work adaptability. \\nCulture Fit Score: Shows adaptability, compliance, and customer focus, which aligns with Fujifilm's values around collaboration, growth, and accountability. Resume indicates openness to learning, fitting Fujifilm's learning/development culture. \\nReadability Score: Resume is clear, logically organized, and easy to read. Education and skills are clearly indicated. \\nGeneration Score: No leakage or copying from JD, structure and detail sufficiently cover a typical entry-level application, but lack direct technical relevance lowers the total score.\"),\n",
       " ResumeEvaluation(skills_score=90, experience_score=85, culture_fit_score=85, readability_score=85, generation_score=90, reasoning=\"Skills Score: The resume demonstrates strong alignment with JD requirements: customer service, cash handling, front-end retail operations, and transaction processing are all present. Minor deduction as community focus and growth mindset are more implicit than explicit. \\n\\nExperience Score: One year of relevant front-end service at Walmart is highly transferable and fits the typical requirements for similar positions at Albertsons. No evidence of team leadership or multi-year depth, but the core experience is strong.\\n\\nCulture Fit Score: Resume describes a commitment to customer service, compliance, and adaptability. While not stating company value-matching language directly, the description shows respect for policy, supporting customers/colleagues, and willingness for shift work—all attributes valued by the JD.\\n\\nReadability Score: The resume is well structured and clearly presents relevant skills and experience. Bullet points and sections are effectively used for clarity.\\n\\nGeneration Score: There is no evidence of JD sentence copying or close paraphrasing, and the content is original, clear, and relevant. The resume is professionally generated with some extra, non-relevant content (data science) which doesn't hurt but also doesn't enhance suitability for this particular retail position.\"),\n",
       " ResumeEvaluation(skills_score=88, experience_score=75, culture_fit_score=85, readability_score=65, generation_score=65, reasoning='Skills Score: The resume lists almost all required skills, including customer service, cash control, front-end management, compliance, retail, and effective communication, closely matching the job description.\\nExperience Score: The experience is solid, with more than one year in relevant retail/customer-facing roles and front-end supervision at King Soopers, but does not specify part-time or shift experience and is not directly at Walmart.\\nCulture Fit Score: The resume references values and experience aligning with Walmart\\'s focus on compliance, inclusion, and service, supporting a strong culture fit.\\nReadability Score: Formatting is choppy (\"Exprience - More than 1 year months\"), with some grammatical issues; sentences are list-like and not fluid, impacting clarity.\\nGeneration Score: No evidence of JD leakage, but repetitiveness, formatting issues, and lack of polished narrative limit overall quality.'),\n",
       " ResumeEvaluation(skills_score=95, experience_score=95, culture_fit_score=95, readability_score=87, generation_score=85, reasoning='Skills Score: The resume directly demonstrates customer service, teamwork, cashiering, community engagement, learning and development, all core to the JD. Little is missing; near-perfect match.\\nExperience Score: 2 years of directly relevant experience in a very similar or the exact same environment (Albertsons) with detailed project and initiative work relevant to the role and company.\\nCulture Fit Score: The resume repeatedly notes community engagement, inclusion, team support, positive attitude, and participation in volunteer activities, aligning closely with JD values.\\nReadability Score: Sentences are clear and organized by role, project, and responsibility, but some repetition and technical segmenting slightly hinder flow.\\nGeneration Score: The resume is original, clearly structured, has almost no leakage from the JD, and aligns well with requirements. However, the format could be streamlined for even stronger clarity and conciseness.'),\n",
       " ResumeEvaluation(skills_score=75, experience_score=70, culture_fit_score=85, readability_score=90, generation_score=80, reasoning=\"Skills Score: The resume demonstrates experience with customer service, cash handling, communication, teamwork, and problem solving, which match several JD requirements. However, it lacks explicit front-end supervisory/management experience and doesn't mention knowledge of food safety or compliance paperwork, which are important for the role. \\nExperience Score: The candidate has relevant retail and customer service experience at Albertsons, with about 18-24 months in various customer-facing roles, but no management or explicit front-end department leadership experience. This fits a junior or associate level well, but doesn't fully meet desired supervisory/management background.\\nCulture Fit Score: The resume indicates alignment with core values—teamwork, customer focus, inclusion, adaptability, and reliability. Statements about fostering belonging and supporting company values suggest strong cultural alignment. \\nReadability Score: The resume is well-structured, uses clear bullet points, and avoids JD paraphrasing. Sentences are concise and readable.\\nGeneration Score: The resume is original, not copied from the JD, and tailored for a customer-facing retail role. It is slightly generic and could be improved by specifying achievements or leadership experience, but overall is of good quality for an entry-level applicant.\")]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bad39f",
   "metadata": {},
   "source": [
    "# 전체 데이터셋 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3654bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가하길 원하는 데이터셋만 로딩\n",
    "path = \"./data\"\n",
    "paths = [os.path.join(path, p) for p in os.listdir(path) if \"resume\" in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9fa40cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/gpt-4.1_resume.csv',\n",
       " './data/gpt-4.1-mini_resume.csv',\n",
       " './data/o4-mini_resume.csv',\n",
       " './data/o3-mini_resume.csv']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 JD활용하여 생성한 CV\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12c3afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩, 저장이름 지정\n",
    "datasets = [pd.read_csv(p) for p in paths]\n",
    "save_name = [i.split(\"/\")[-1].split(\"_resume.csv\")[0] for i in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c3f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [13:31<00:00, 13.53s/it]\n",
      "100%|██████████| 60/60 [13:46<00:00, 13.78s/it]\n",
      "100%|██████████| 60/60 [13:14<00:00, 13.23s/it]\n",
      "100%|██████████| 60/60 [14:02<00:00, 14.04s/it]\n"
     ]
    }
   ],
   "source": [
    "results = defaultdict(list)\n",
    "for index, dataset in enumerate(datasets):\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        one_sample = dataset.iloc[i]\n",
    "\n",
    "        jd = one_sample[\"jd\"]\n",
    "        gen_cv = one_sample[\"generated_cv\"]\n",
    "        results[save_name[index]].append(evaluate_gen_cv(jd, gen_cv=gen_cv, model=\"o3-mini\", temperature=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64bd5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gpt-4.1', 'gpt-4.1-mini', 'o4-mini', 'o3-mini'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 데이터프레임에 평가 점수 추가\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    skill_score = [result.skills_score for result in results[save_name[i]]]\n",
    "    experience_score = [result.experience_score for result in results[save_name[i]]]\n",
    "    culture_fit_score = [result.culture_fit_score for result in results[save_name[i]]]\n",
    "    readability_score = [result.readability_score for result in results[save_name[i]]]\n",
    "    generation_score = [result.generation_score for result in results[save_name[i]]]\n",
    "    reasoning = [result.reasoning for result in results[save_name[i]]]\n",
    "\n",
    "    datasets[i][\"skill_score\"] = skill_score\n",
    "    datasets[i][\"experience_score\"] = experience_score\n",
    "    datasets[i][\"culture_fit_score\"] = culture_fit_score\n",
    "    datasets[i][\"readability_score\"] = readability_score\n",
    "    datasets[i][\"generation_score\"] = generation_score\n",
    "    datasets[i][\"reasoning\"] = reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee4e123",
   "metadata": {},
   "source": [
    "<!-- ### 원본jd, resume+평가 점수 csv 저장 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(datasets):\n",
    "    dataset.to_csv(f\"./data/evaluation/{save_name[i]}_evaluation2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a2d520",
   "metadata": {},
   "source": [
    "<!-- # 점수 총합 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d958fcd9",
   "metadata": {},
   "source": [
    "# 평가 후 데이터셋 로딩 후 결과확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b166fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"./data/evaluation\"\n",
    "eval_paths = [os.path.join(eval_path, p) for p in os.listdir(eval_path) if p.endswith(\"evaluation2.csv\")]\n",
    "model_name = [os.path.basename(p).split(\"_evaluation.csv\")[0] for p in eval_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ecec236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/evaluation/o3-mini_evaluation2.csv',\n",
       " './data/evaluation/gpt-4.1-mini_evaluation2.csv',\n",
       " './data/evaluation/o4-mini_evaluation2.csv',\n",
       " './data/evaluation/gpt-4.1_evaluation2.csv']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "273eebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_datasets = [pd.read_csv(p) for p in eval_paths]\n",
    "score_dicts = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb8df446",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(eval_datasets):\n",
    "    score_dicts[model_name[i]][\"skill_score\"] = sum(dataset[\"skill_score\"])\n",
    "    score_dicts[model_name[i]][\"experience_score\"] = sum(dataset[\"experience_score\"])\n",
    "    score_dicts[model_name[i]][\"culture_fit_score\"] = sum(dataset[\"culture_fit_score\"])\n",
    "    score_dicts[model_name[i]][\"readability_score\"] = sum(dataset[\"readability_score\"])\n",
    "    score_dicts[model_name[i]][\"generation_score\"] = sum(dataset[\"generation_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79a47eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'o3-mini_evaluation2.csv': {'skill_score': 5030,\n",
       "              'experience_score': 4735,\n",
       "              'culture_fit_score': 4635,\n",
       "              'readability_score': 4955,\n",
       "              'generation_score': 3830},\n",
       "             'gpt-4.1-mini_evaluation2.csv': {'skill_score': 5360,\n",
       "              'experience_score': 5080,\n",
       "              'culture_fit_score': 5080,\n",
       "              'readability_score': 5225,\n",
       "              'generation_score': 2540},\n",
       "             'o4-mini_evaluation2.csv': {'skill_score': 5325,\n",
       "              'experience_score': 5060,\n",
       "              'culture_fit_score': 4920,\n",
       "              'readability_score': 5095,\n",
       "              'generation_score': 3145},\n",
       "             'gpt-4.1_evaluation2.csv': {'skill_score': 5235,\n",
       "              'experience_score': 4975,\n",
       "              'culture_fit_score': 5045,\n",
       "              'readability_score': 5045,\n",
       "              'generation_score': 2665}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c3076fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[o3-mini_evaluation2.csv] Total Score:  23185\n",
      "[o3-mini_evaluation2.csv] Without generation_score:  19355\n",
      "\n",
      "[gpt-4.1-mini_evaluation2.csv] Total Score:  23285\n",
      "[gpt-4.1-mini_evaluation2.csv] Without generation_score:  20745\n",
      "\n",
      "[o4-mini_evaluation2.csv] Total Score:  23545\n",
      "[o4-mini_evaluation2.csv] Without generation_score:  20400\n",
      "\n",
      "[gpt-4.1_evaluation2.csv] Total Score:  22965\n",
      "[gpt-4.1_evaluation2.csv] Without generation_score:  20300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in score_dicts.items():\n",
    "    #generation_score는 추후 필터링용\n",
    "    print(f\"[{key}] Total Score: \", sum(list(value.values())))\n",
    "    print(f\"[{key}] Without generation_score: \", sum(list(value.values())[:-1]))\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84e7defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # culture가 ATS에서 크게 중요한 요소는 아닌데 점수 편차가 커보여서 가중을 낮게 줘서 다시 계산\n",
    "# total_score = defaultdict(dict)\n",
    "# for key, value in score_dicts.items():\n",
    "#     model = key\n",
    "#     skill, experience, culture, readibe = value.values()\n",
    "#     total_score[model]=skill*0.50 + experience*0.30 + culture*0.10 + readibe*0.10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
